# ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡ - ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
# 2025-11-07, ê¹€ë³‘í˜„ ì‘ì„±

import torch
from kobert_tokenizer import KoBERTTokenizer
from src.models.sentence_order_model import SentenceOrderPredictor


def predict_sentence_order(sentences, model_path='models/sentence_order_model_best.pt'):
    """
    ë¬¸ì¥ë“¤ì˜ ì˜¬ë°”ë¥¸ ìˆœì„œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

    Args:
        sentences: List[str] - ì„ì¸ ìˆœì„œì˜ ë¬¸ì¥ë“¤
        model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ

    Returns:
        sorted_sentences: List[str] - ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì •ë ¬ëœ ë¬¸ì¥ë“¤
        predicted_order: List[int] - ì˜ˆì¸¡ëœ ìˆœì„œ ì¸ë±ìŠ¤
    """
    # Device ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')

    # ëª¨ë¸ ë¡œë“œ
    model = SentenceOrderPredictor(max_sentences=5)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)

    # ìˆœì„œ ì˜ˆì¸¡
    predicted_order = model.predict_order(sentences, tokenizer, device)

    # ìˆœì„œëŒ€ë¡œ ë¬¸ì¥ ì •ë ¬
    # predicted_order[i] = j ì˜ë¯¸: ië²ˆì§¸ ë¬¸ì¥ì´ jë²ˆì§¸ ìœ„ì¹˜ì— ìˆì–´ì•¼ í•¨
    sorted_sentences = [None] * len(sentences)
    for i, position in enumerate(predicted_order):
        if position < len(sentences):  # ìœ íš¨í•œ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
            sorted_sentences[position] = sentences[i]

    # None ì œê±° (ì˜ˆì¸¡ì´ ì˜ëª»ëœ ê²½ìš° ëŒ€ë¹„)
    sorted_sentences = [s for s in sorted_sentences if s is not None]

    return sorted_sentences, predicted_order


# ==================== ì˜ˆì‹œ ì‹¤í–‰ ====================

if __name__ == "__main__":
    print("=" * 70)
    print("ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡ - ì¶”ë¡ ")
    print("=" * 70)

    # í…ŒìŠ¤íŠ¸ ì˜ˆì‹œë“¤
    test_cases = [
        {
            "name": "ì•„ì¹¨ ë£¨í‹´",
            "sentences": [
                "í•™êµì— ê°”ë‹¤",
                "ì¼ì–´ë‚¬ë‹¤",
                "ë°¥ì„ ë¨¹ì—ˆë‹¤",
                "ì„¸ìˆ˜ë¥¼ í–ˆë‹¤",
                "ì˜·ì„ ì…ì—ˆë‹¤"
            ]
        },
        {
            "name": "ìš”ë¦¬ ê³¼ì •",
            "sentences": [
                "ì ‘ì‹œì— ë‹´ì•˜ë‹¤",
                "ì¬ë£Œë¥¼ ì†ì§ˆí–ˆë‹¤",
                "ì¬ë£Œë¥¼ ì¤€ë¹„í–ˆë‹¤",
                "íŒ¬ì— ë³¶ì•˜ë‹¤",
                "ê°„ì„ ë§ì·„ë‹¤"
            ]
        },
        {
            "name": "ê³µë¶€í•˜ê¸°",
            "sentences": [
                "ì±„ì ì„ í–ˆë‹¤",
                "ë¬¸ì œë¥¼ ì½ì—ˆë‹¤",
                "ë‹µì„ ì ì—ˆë‹¤",
                "êµê³¼ì„œë¥¼ íˆë‹¤",
                "í’€ì´ë¥¼ ìƒê°í–ˆë‹¤"
            ]
        }
    ]

    # ëª¨ë¸ ê²½ë¡œ í™•ì¸
    import os
    model_path = 'models/sentence_order_model_best.pt'

    if not os.path.exists(model_path):
        print(f"\nâš ï¸  ê²½ê³ : í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   ë¨¼ì € 'python train_sentence_order.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        print(f"\nğŸ’¡ í•™ìŠµ ì—†ì´ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print(f"   python sentence_order_model.py")
        exit(1)

    # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*70}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {test_case['name']}")
        print(f"{'='*70}")

        sentences = test_case['sentences']

        print(f"\nğŸ“¥ ì…ë ¥ (ì„ì¸ ìˆœì„œ):")
        for j, sent in enumerate(sentences):
            print(f"   [{j}] {sent}")

        # ì˜ˆì¸¡
        sorted_sentences, predicted_order = predict_sentence_order(sentences, model_path)

        print(f"\nğŸ“Š ì˜ˆì¸¡ëœ ìˆœì„œ: {predicted_order}")
        print(f"   ì˜ë¯¸: ì…ë ¥ ë¬¸ì¥ {list(range(len(sentences)))}ì´ ìˆœì„œ {predicted_order}ì— ìœ„ì¹˜")

        print(f"\nğŸ“¤ ì¶œë ¥ (ì˜¬ë°”ë¥¸ ìˆœì„œ):")
        for j, sent in enumerate(sorted_sentences):
            print(f"   [{j}] {sent}")

    print(f"\n{'='*70}")
    print("âœ… ì¶”ë¡  ì™„ë£Œ!")
    print(f"{'='*70}")

    # ì‚¬ìš©ì ì…ë ¥ ëª¨ë“œ
    print(f"\nğŸ’¡ ì§ì ‘ ë¬¸ì¥ì„ ì…ë ¥í•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print(f"   (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥)")

    while True:
        print(f"\n" + "-" * 70)
        user_input = input("ë¬¸ì¥ë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: ë°¥ì„ ë¨¹ì—ˆë‹¤, ì¼ì–´ë‚¬ë‹¤, í•™êµì— ê°”ë‹¤): ")

        if user_input.strip().lower() == 'q':
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ì…ë ¥ íŒŒì‹±
        sentences = [s.strip() for s in user_input.split(',') if s.strip()]

        if len(sentences) < 2:
            print("âš ï¸  ìµœì†Œ 2ê°œ ì´ìƒì˜ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        if len(sentences) > 5:
            print("âš ï¸  ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤. ì²˜ìŒ 5ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            sentences = sentences[:5]

        print(f"\nì…ë ¥ëœ ë¬¸ì¥ ({len(sentences)}ê°œ):")
        for j, sent in enumerate(sentences):
            print(f"   [{j}] {sent}")

        # ì˜ˆì¸¡
        sorted_sentences, predicted_order = predict_sentence_order(sentences, model_path)

        print(f"\nì˜ˆì¸¡ëœ ìˆœì„œ: {predicted_order}")
        print(f"\nì˜¬ë°”ë¥¸ ìˆœì„œ:")
        for j, sent in enumerate(sorted_sentences):
            print(f"   [{j}] {sent}")
